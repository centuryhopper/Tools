Transcript 0:00 0:02 0:04 0:08 0:13 0:15 0:19 0:21 0:23 0:25 0:27 0:30 0:32 0:34 0:37 0:38 0:41 0:43 0:48 0:50 0:52 0:57 1:00 1:05 1:08 1:11 1:13 1:15 1:19 1:26 1:29 1:32 1:36 1:40 1:43 1:45 1:48 1:50 1:53 Classification example this digit and I want those to be the inputs to this perceptron and I want the output to tell me a set of probabilities as to which digit it is so the output should look something like you know there's a point one chance it's zero there's a point two chances of one there's a point one chance' two two zero three four five six seven oh it it's like a point ninety nine chances at eight and 0.05 chance it's a ten and I don't think I got those to add up to one but you get the idea so the idea here is that we want to be able to have some type of processing unit that can take it arbitrary amount of inputs like maybe this is a 28 by 28 pixel image so there's 784 grayscale values and instead those are coming into the processor which was wait is it sudden and all this stuff when we get an output that have some arbitrary amounts of probabilities to mitla help us guess eight not that this is an eight this model why couldn't I just have a whole bunch more inputs and then a whole bunch more outputs but still have one single processing unit and the reason why I can't is a stems from an article I don't know I'm sorry a book that was published in 1969 by 3:21 3:23 3:26 3:29 3:35 3:38 3:41 3:44 3:47 Linearly separable problems let's think about this this over here is a linearly separable problem meaning I need to classify this stuff and if I were to visualize all that stuff I can draw a line in between this part of the day this this stuff is to this class and this stuff that's with this class the stuff itself is separable by a line in three dimensions I could put a plane and that would be literally separable because I can kind of divide the space in half and and and understand it that way the problem is most interesting problems are not linearly separable you know there might be some Dana which clusters all here in the center that is of one class but anything outside of it is of another class and I can't draw one line to separate that stuff and you might be even thinking but that's you know still so much you could do so much with linearly separable stuff well here I'm going to show you right now a particular problem I'm looking for an eraser logging around like a crazy person I'm going to show you a particular problem called X or I'm making the case for why 5:10 5:13 5:15 5:17 5:21 5:23 5:25 5:27 5:30 5:32 5:34 5:38 5:41 5:43 5:46 5:51 5:58 6:00 6:07 6:13 6:16 6:20 6:24 6:29 6:34 6:38 6:43 6:46 6:49 6:51 6:53 6:56 6:59 7:02 7:05 7:08 7:10 7:12 7:14 7:16 7:19 7:21 7:24 7:26 7:27 7:30 7:32 7:36 7:40 7:42 7:46 7:50 7:52 7:54 7:59 8:01 8:04 8:08 8:12 8:14 8:16 8:17 8:18 8:21 8:24 8:30 8:36 8:38 8:42 8:44 8:46 8:49 8:58 9:02 9:04 9:06 9:10 9:13 9:20 9:23 9:27 9:29 9:31 9:33 9:39 9:40 9:42 9:46 9:50 9:52 9:54 9:56 10:00 10:01 10:04 10:08 10:09 10:12 10:13 10:18 10:23 10:26 10:29 10:33 10:38 10:41 10:44 10:50 10:54 10:57 11:01 11:02 11:04 11:11 11:13 11:15 11:17 11:21 11:23 11:25 11:29 11:31 11:34 11:37 11:40 11:47 11:49 11:51 11:53 11:55 11:57 12:00 12:02 12:06 12:08 12:12 12:14 12:17 12:18 12:20 12:21 12:24 12:26 12:29 12:32 12:35 12:37 12:40 12:42 12:45 12:47 12:51 12:53 12:55 12:58 12:59 13:02 13:03 13:05 13:06 13:08 13:10 13:12 13:13 13:14 13:16 13:18 13:21 13:24 13:26 13:28 13:31 13:35 13:38 13:41 13:45 13:51 13:52 13:55 13:57 14:00 14:02 14:06 14:08 14:11 14:12 14:15 14:17 14:18 14:20 14:22 14:25 14:26 14:31 14:34 14:35 14:37 14:39 14:41 14:43 14:44 14:47 14:50 14:51 14:52 14:55 14:57 14:59 15:01 15:03 15:04 15:06 15:08 15:11 15:13 15:14 15:16 15:18 15:21 Outro building the library and to be honest I think what I need to do yeah the next video I'm going to set up the basic skeleton of the neural network library and look at all the pieces that we need and then I'm going to have to keep going and look at some matrix math that's going to be fun okay see you soon [Music]
